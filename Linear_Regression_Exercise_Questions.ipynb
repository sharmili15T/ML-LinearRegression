{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are interested in building a model that will predict housing values in Boston suburbs using\n",
    "various predictor variables that you have available. This is your data set: boston.csv (the\n",
    "number of attributes has been reduced from the original form)\n",
    "Use Multiple Linear Regression to build your model, with the median value of owner-occupied\n",
    "homes as the target variable and the rest as predictors.\n",
    "Determine the significance of these different predictors, and drop the ones that are not useful for\n",
    "your model. \n",
    "Document your work and explain your decision making as you build your model. \n",
    "Report your final model's accuracy - R2, MSE and MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set Info:\n",
    "Title: Boston Housing Data\n",
    "Information: Concerns housing values in suburbs of Boston.\n",
    "Number of Observations: 506\n",
    "Number of Attributes: 9 (Original data set has 13 variables)\n",
    "Attribute Information:\n",
    "1. CRIM per capita crime rate by town\n",
    "2. INDUS proportion of non-retail business acres per town\n",
    "3. NOX nitric oxides concentration (parts per 10 million)\n",
    "4. RM average number of rooms per dwelling\n",
    "5. AGE proportion of owner-occupied units built prior to 1940\n",
    "6. DIS weighted distances to five Boston employment centres\n",
    "7. TAX full-value property-tax rate per 10000(dollars)\n",
    "8. PT pupil-teacher ratio by town\n",
    "9. B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "10. MV Median value of owner-occupied homes in 1000's(dollars)\n",
    "\n",
    "For more information on this dataset, see https://archive.ics.uci.edu/ml/machine-learning-\n",
    "databases/housing/housing.names (https://archive.ics.uci.edu/ml/machine-learning-\n",
    "databases/housing/housing.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file into pandas and preview data using head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values in all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation heatmap and note down observations\n",
    "# hint: provide annot=TRUE to see the values in the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train/test class from sklearn module to split data into training and testing\n",
    "# Using 80% of data as the training set and 20% as the test set\n",
    "# Since MV (median home value) is the response variable of interest, dropping 'MV' from the train set and putting 'MV'\n",
    "# as the test variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add constant term sm.add_constant to X_train and X_test\n",
    "## By default, statsmodels fits a line passing through the origin, i.e. it doesn't fit an intercept. \n",
    "## Hence, you need to use thecommand 'add_constant' so that it also fits an intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model summary - note down the R-squared and adj R-squared. \n",
    "# observe the p-values and note down insignificant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepwise Backward Regression:\n",
    "# drop the feature with the highest p-value from train data \n",
    "# (for this data - 2 iterations are required - i.e, you will drop around 2 insignificant features - find out which and why)\n",
    "# fit the model again and print the summary\n",
    "# observe the report \n",
    "# repeat the process of dropping features (one by one) till only significant features are left\n",
    "# This will be the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the final model - obtain the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r2_score, mean_squared_error and mean_absolute_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
